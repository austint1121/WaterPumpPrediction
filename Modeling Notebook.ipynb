{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b2379c1",
   "metadata": {},
   "source": [
    "# Data Cleaning Notebook\n",
    "In this notebook, I will be cleaning the notebook, and preparing a pipeline for use in the modeling process. Then later, I will use the pipleline to create some basic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b97688dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b70d1d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data into dataframe\n",
    "X_train = pd.read_csv('./Data/Training_Features.csv')\n",
    "\n",
    "X_test = pd.read_csv('./Data/Test_Features.csv')\n",
    "\n",
    "y_train = pd.read_csv('./Data/Training_Labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2d03dc",
   "metadata": {},
   "source": [
    "## Labels\n",
    "The only thing that needs to be done to the label dataframes is encoding. The string values need to be turned into numbers. For simplicity, I'll do it by hand rather then using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b7d7d18d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional                 32259\n",
       "non functional             22824\n",
       "functional needs repair     4317\n",
       "Name: status_group, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d27b4ce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    32259\n",
       "0    22824\n",
       "2     4317\n",
       "Name: status_group, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordinally encoding the target.\n",
    "y_train['status_group'].replace({'functional': 1, 'non functional': 0, 'functional needs repair': 2}, inplace=True)\n",
    "y_train['status_group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b796d17",
   "metadata": {},
   "source": [
    "## Features and Pipeline\n",
    "I'll need to do these things before modeling:\n",
    "- Imputing NaN values\n",
    "- Ordinal encoding\n",
    "- One hot encoding\n",
    "\n",
    "These I'll need to have a seperate way of dealing with NaN values depending on if the object type of the column is numreric or not. I will also need to encode the non-numeric features. I plan to use OHE for anything with < 10 unique values, and ordinal encode for anything with > 10 unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c93f16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize three columns\n",
    "num_cols = []\n",
    "ohe_cols = []\n",
    "ord_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a43b105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the lists of columns\n",
    "# num = any columns with numerical value\n",
    "# ohe = any columns with object value with less than 10 unique values\n",
    "# ord = any columns with object value with 10 or more unique values\n",
    "for c in X_train.columns:\n",
    "    if X_train[c].dtype in ['float64', 'int64']:\n",
    "        num_cols.append(c)\n",
    "    elif X_train[c].nunique() < 10:\n",
    "        ohe_cols.append(c)\n",
    "    else:\n",
    "        ord_cols.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a096f324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, the numeric columns.\n",
    "num_transformer = Pipeline(steps=[\n",
    "    # Fill the unknown value with the median value for the column\n",
    "    ('num_imputer', SimpleImputer(strategy='median'))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ca62fcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_transformer = Pipeline(steps=[\n",
    "    # For each unknown value, fill in \"Unknown\".\n",
    "    ('ohe_imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "    # One Hot encode, and ignore unknown categories\n",
    "    ('oh_encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "ord_transformer = Pipeline(steps=[\n",
    "    # For each unknown value, fill in \"Unknown\".\n",
    "    ('ord_imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "    # Ordinal encode, and ignore unknown categories\n",
    "    ('ord_encoder', OrdinalEncoder(handle_unknown='ignore')),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "603d7754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the transformers have been set up, package them together into a transformer.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', num_transformer, num_cols),\n",
    "        ('ohe', ohe_transformer, ohe_cols),\n",
    "        ('ord', ord_transformer, ord_cols)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfe888e",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "Now, I'll use this pipeline to create some simple models. The competition is using accuracy as the primary evaluation metric, so I'll do the same moving forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33d75a9",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Let's start small with a simple logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f68a91ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline with prep\n",
    "lr_pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('LogisticReg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06655bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KaggleJTP",
   "language": "python",
   "name": "kagglejtp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
