{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Notebook\n",
    "In this notebook, I will be cleaning the notebook, and preparing a pipeline for use in the modeling process. Then later, I will use the pipleline to create some basic models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "sns.set(rc={'figure.figsize':(11.7,8.27)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data into dataframe\n",
    "X_train = pd.read_csv('./Data/Training_Features.csv')\n",
    "X_train.drop(columns=['date_recorded', 'permit', 'public_meeting'], inplace=True)\n",
    "X_test = pd.read_csv('./Data/Test_Features.csv')\n",
    "\n",
    "y_train = pd.read_csv('./Data/Training_Labels.csv')\n",
    "y_train = y_train['status_group']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels\n",
    "The only thing that needs to be done to the label dataframes is encoding. The string values need to be turned into numbers. For simplicity, I'll do it by hand rather then using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "functional                 32259\n",
       "non functional             22824\n",
       "functional needs repair     4317\n",
       "Name: status_group, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    32259\n",
       "0    22824\n",
       "2     4317\n",
       "Name: status_group, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordinally encoding the target.\n",
    "y_train.replace({'functional': 1, 'non functional': 0, 'functional needs repair': 2}, inplace=True)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Pipeline\n",
    "I'll need to do these things before modeling:\n",
    "- Imputing NaN values\n",
    "- Ordinal encoding\n",
    "- One hot encoding\n",
    "\n",
    "These I'll need to have a seperate way of dealing with NaN values depending on if the object type of the column is numreric or not. I will also need to encode the non-numeric features. I plan to use OHE for non-numeric columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize three columns\n",
    "num_cols = []\n",
    "ohe_cols = []\n",
    "ord_cols = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the lists of columns\n",
    "# num = any columns with numerical value\n",
    "# ohe = any columns with object value\n",
    "for c in X_train.columns:\n",
    "    if X_train[c].dtype in ['float64', 'int64']:\n",
    "        num_cols.append(c)\n",
    "    else:\n",
    "        ohe_cols.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, the numeric columns.\n",
    "num_transformer = Pipeline(steps=[\n",
    "    # Fill the unknown value with the median value for the column\n",
    "    ('num_imputer', SimpleImputer(strategy='median')),\n",
    "    ('StandardScaler', MinMaxScaler())\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_transformer = Pipeline(steps=[\n",
    "    # For each unknown value, fill in \"Unknown\".\n",
    "    ('ohe_imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "    # One Hot encode, and ignore unknown categories\n",
    "    ('oh_encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the transformers have been set up, package them together into a transformer.\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('numeric', num_transformer, num_cols),\n",
    "        ('ohe', ohe_transformer, ohe_cols),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "Now, I'll use this pipeline to create some simple models. The competition is using accuracy as the primary evaluation metric, so I'll do the same moving forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression\n",
    "Let's start small with a simple logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline with preprocessor and Logistic Regression predictor\n",
    "lr_pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    # Using 'saga' solver because default solver \"lbfgs\" was not converging\n",
    "    ('LogisticReg', LogisticRegression(solver='saga', random_state=15))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross validate since we don't have access to the testing labels\n",
    "lr_scores = cross_validate(lr_pipe, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7891414141414141"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print mean of all test scores\n",
    "np.mean(lr_scores['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "The baseline logistic regression model scored about 0.78 / 0.79 accuracy. The model will almost certainly perform worse on the test data, but this is about what I would expect from this model type with no tuning. Let's also test a decision tree model, and see if it performs better then a logistic regresson model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn Decision Tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DT pipeline.\n",
    "dt_pipe = Pipeline(steps=[\n",
    "    ('dt_preprocessor', preprocessor),\n",
    "    ('DecisionTree', DecisionTreeClassifier(max_depth=20, random_state=15))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7808080808080808"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validate and return mean accuracy of all folds\n",
    "dt_scores = cross_validate(dt_pipe, X_train, y_train)\n",
    "np.mean(dt_scores['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "The decision tree performed similarly to the LR model, but did slightly worse. This decision tree would perform better with a few more hyper parameter tweaks as well. Moving forward any advanced models I try should perform better then these two models I've created thus far."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosted Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for the gradient boosted classifer\n",
    "gb_pipe = Pipeline(steps=[\n",
    "    ('gb_preprocessor', preprocessor),\n",
    "    ('GradientBoost', GradientBoostingClassifier(random_state=15))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7601683501683503"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validate and return mean accuracy of all folds\n",
    "gb_scores = cross_validate(gb_pipe, X_train, y_train)\n",
    "np.mean(gb_scores['test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "This does slightly worse then a baseline decision tree and logistic regression. This is a bit of a suprising result since normally GB classifiers perform better then LR or DT models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KaggleJTP",
   "language": "python",
   "name": "kagglejtp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
