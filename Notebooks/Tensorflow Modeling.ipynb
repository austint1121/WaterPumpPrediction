{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3f012d",
   "metadata": {},
   "source": [
    "# Tensorflow Neural Network\n",
    "In this notebook, I'll take the data, and preprocess it using Tensorflow, and then create a baseline neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c33b54f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages and libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "987a5f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>amount_tsh</th>\n",
       "      <th>gps_height</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>wpt_name</th>\n",
       "      <th>num_private</th>\n",
       "      <th>basin</th>\n",
       "      <th>region</th>\n",
       "      <th>region_code</th>\n",
       "      <th>...</th>\n",
       "      <th>water_quality</th>\n",
       "      <th>quality_group</th>\n",
       "      <th>quantity</th>\n",
       "      <th>quantity_group</th>\n",
       "      <th>source</th>\n",
       "      <th>source_type</th>\n",
       "      <th>source_class</th>\n",
       "      <th>waterpoint_type</th>\n",
       "      <th>waterpoint_type_group</th>\n",
       "      <th>status_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69572</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>1390</td>\n",
       "      <td>34.938093</td>\n",
       "      <td>-9.856322</td>\n",
       "      <td>none</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Nyasa</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8776</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1399</td>\n",
       "      <td>34.698766</td>\n",
       "      <td>-2.147466</td>\n",
       "      <td>Zahanati</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Mara</td>\n",
       "      <td>20</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34310</td>\n",
       "      <td>25.0</td>\n",
       "      <td>686</td>\n",
       "      <td>37.460664</td>\n",
       "      <td>-3.821329</td>\n",
       "      <td>Kwa Mahundi</td>\n",
       "      <td>0</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>Manyara</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>dam</td>\n",
       "      <td>dam</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263</td>\n",
       "      <td>38.486161</td>\n",
       "      <td>-11.155298</td>\n",
       "      <td>Zahanati Ya Nanyumbu</td>\n",
       "      <td>0</td>\n",
       "      <td>Ruvuma / Southern Coast</td>\n",
       "      <td>Mtwara</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>dry</td>\n",
       "      <td>dry</td>\n",
       "      <td>machine dbh</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe multiple</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19728</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.130847</td>\n",
       "      <td>-1.825359</td>\n",
       "      <td>Shuleni</td>\n",
       "      <td>0</td>\n",
       "      <td>Lake Victoria</td>\n",
       "      <td>Kagera</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>seasonal</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>rainwater harvesting</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59395</th>\n",
       "      <td>60739</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1210</td>\n",
       "      <td>37.169807</td>\n",
       "      <td>-3.253847</td>\n",
       "      <td>Area Three Namba 27</td>\n",
       "      <td>0</td>\n",
       "      <td>Pangani</td>\n",
       "      <td>Kilimanjaro</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>spring</td>\n",
       "      <td>spring</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59396</th>\n",
       "      <td>27263</td>\n",
       "      <td>4700.0</td>\n",
       "      <td>1212</td>\n",
       "      <td>35.249991</td>\n",
       "      <td>-9.070629</td>\n",
       "      <td>Kwa Yahona Kuvala</td>\n",
       "      <td>0</td>\n",
       "      <td>Rufiji</td>\n",
       "      <td>Iringa</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>river</td>\n",
       "      <td>river/lake</td>\n",
       "      <td>surface</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>communal standpipe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59397</th>\n",
       "      <td>37057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.017087</td>\n",
       "      <td>-8.750434</td>\n",
       "      <td>Mashine</td>\n",
       "      <td>0</td>\n",
       "      <td>Rufiji</td>\n",
       "      <td>Mbeya</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>fluoride</td>\n",
       "      <td>fluoride</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>machine dbh</td>\n",
       "      <td>borehole</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59398</th>\n",
       "      <td>31282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.861315</td>\n",
       "      <td>-6.378573</td>\n",
       "      <td>Mshoro</td>\n",
       "      <td>0</td>\n",
       "      <td>Rufiji</td>\n",
       "      <td>Dodoma</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>soft</td>\n",
       "      <td>good</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>insufficient</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59399</th>\n",
       "      <td>26348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>191</td>\n",
       "      <td>38.104048</td>\n",
       "      <td>-6.747464</td>\n",
       "      <td>Kwa Mzee Lugawa</td>\n",
       "      <td>0</td>\n",
       "      <td>Wami / Ruvu</td>\n",
       "      <td>Morogoro</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>salty</td>\n",
       "      <td>salty</td>\n",
       "      <td>enough</td>\n",
       "      <td>enough</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>shallow well</td>\n",
       "      <td>groundwater</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>hand pump</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59400 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  amount_tsh  gps_height  longitude   latitude  \\\n",
       "0      69572      6000.0        1390  34.938093  -9.856322   \n",
       "1       8776         0.0        1399  34.698766  -2.147466   \n",
       "2      34310        25.0         686  37.460664  -3.821329   \n",
       "3      67743         0.0         263  38.486161 -11.155298   \n",
       "4      19728         0.0           0  31.130847  -1.825359   \n",
       "...      ...         ...         ...        ...        ...   \n",
       "59395  60739        10.0        1210  37.169807  -3.253847   \n",
       "59396  27263      4700.0        1212  35.249991  -9.070629   \n",
       "59397  37057         0.0           0  34.017087  -8.750434   \n",
       "59398  31282         0.0           0  35.861315  -6.378573   \n",
       "59399  26348         0.0         191  38.104048  -6.747464   \n",
       "\n",
       "                   wpt_name  num_private                    basin  \\\n",
       "0                      none            0               Lake Nyasa   \n",
       "1                  Zahanati            0            Lake Victoria   \n",
       "2               Kwa Mahundi            0                  Pangani   \n",
       "3      Zahanati Ya Nanyumbu            0  Ruvuma / Southern Coast   \n",
       "4                   Shuleni            0            Lake Victoria   \n",
       "...                     ...          ...                      ...   \n",
       "59395   Area Three Namba 27            0                  Pangani   \n",
       "59396     Kwa Yahona Kuvala            0                   Rufiji   \n",
       "59397               Mashine            0                   Rufiji   \n",
       "59398                Mshoro            0                   Rufiji   \n",
       "59399       Kwa Mzee Lugawa            0              Wami / Ruvu   \n",
       "\n",
       "            region  region_code  ...  water_quality quality_group  \\\n",
       "0           Iringa           11  ...           soft          good   \n",
       "1             Mara           20  ...           soft          good   \n",
       "2          Manyara           21  ...           soft          good   \n",
       "3           Mtwara           90  ...           soft          good   \n",
       "4           Kagera           18  ...           soft          good   \n",
       "...            ...          ...  ...            ...           ...   \n",
       "59395  Kilimanjaro            3  ...           soft          good   \n",
       "59396       Iringa           11  ...           soft          good   \n",
       "59397        Mbeya           12  ...       fluoride      fluoride   \n",
       "59398       Dodoma            1  ...           soft          good   \n",
       "59399     Morogoro            5  ...          salty         salty   \n",
       "\n",
       "           quantity  quantity_group                source  \\\n",
       "0            enough          enough                spring   \n",
       "1      insufficient    insufficient  rainwater harvesting   \n",
       "2            enough          enough                   dam   \n",
       "3               dry             dry           machine dbh   \n",
       "4          seasonal        seasonal  rainwater harvesting   \n",
       "...             ...             ...                   ...   \n",
       "59395        enough          enough                spring   \n",
       "59396        enough          enough                 river   \n",
       "59397        enough          enough           machine dbh   \n",
       "59398  insufficient    insufficient          shallow well   \n",
       "59399        enough          enough          shallow well   \n",
       "\n",
       "                source_type source_class              waterpoint_type  \\\n",
       "0                    spring  groundwater           communal standpipe   \n",
       "1      rainwater harvesting      surface           communal standpipe   \n",
       "2                       dam      surface  communal standpipe multiple   \n",
       "3                  borehole  groundwater  communal standpipe multiple   \n",
       "4      rainwater harvesting      surface           communal standpipe   \n",
       "...                     ...          ...                          ...   \n",
       "59395                spring  groundwater           communal standpipe   \n",
       "59396            river/lake      surface           communal standpipe   \n",
       "59397              borehole  groundwater                    hand pump   \n",
       "59398          shallow well  groundwater                    hand pump   \n",
       "59399          shallow well  groundwater                    hand pump   \n",
       "\n",
       "      waterpoint_type_group status_group  \n",
       "0        communal standpipe            1  \n",
       "1        communal standpipe            1  \n",
       "2        communal standpipe            1  \n",
       "3        communal standpipe            0  \n",
       "4        communal standpipe            1  \n",
       "...                     ...          ...  \n",
       "59395    communal standpipe            1  \n",
       "59396    communal standpipe            1  \n",
       "59397             hand pump            1  \n",
       "59398             hand pump            1  \n",
       "59399             hand pump            1  \n",
       "\n",
       "[59400 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training data into dataframe\n",
    "X_train = pd.read_csv('../Data/Training_Features.csv')\n",
    "X_train.drop(columns=['date_recorded', 'permit', 'public_meeting'], inplace=True)\n",
    "# Drop columns with NaN values\n",
    "X_train.dropna(axis=1, inplace=True)\n",
    "\n",
    "y_train = pd.read_csv('../Data/Training_Labels.csv')\n",
    "\n",
    "# Ordinally encoding the target.\n",
    "y_train.replace({'functional': 1, 'non functional': 0, 'functional needs repair': 2}, inplace=True)\n",
    "\n",
    "# Merge data into one frame using the ID column\n",
    "combined_frame = pd.merge(X_train, y_train, on='id')\n",
    "combined_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72206520",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99dee0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train, validation, and test set\n",
    "train, val, test = np.split(combined_frame.sample(frac=1), [int(0.8*len(combined_frame)), int(0.9*len(combined_frame))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b2cdea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47520 training examples\n",
      "5940 validation examples\n",
      "5940 test examples\n"
     ]
    }
   ],
   "source": [
    "# Confirm expected results\n",
    "print(len(train), 'training examples')\n",
    "print(len(val), 'validation examples')\n",
    "print(len(test), 'test examples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2666c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to convert dataframe to a Tensorflow dataset object\n",
    "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
    "    df = dataframe.copy()\n",
    "    labels = df.pop('status_group')\n",
    "    df = {key: value[:,tf.newaxis] for key, value in dataframe.items()}\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "    ds = ds.batch(batch_size)\n",
    "    ds = ds.prefetch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c3783ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y8/vq429chs6djb0hl0y0zp5fg00000gn/T/ipykernel_39053/1929805004.py:5: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  df = {key: value[:,tf.newaxis] for key, value in dataframe.items()}\n",
      "2022-02-03 13:51:22.683437: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Set batch size and run method on training data\n",
    "batch_size = 5\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb4782c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every feature: ['id', 'amount_tsh', 'gps_height', 'longitude', 'latitude', 'wpt_name', 'num_private', 'basin', 'region', 'region_code', 'district_code', 'lga', 'ward', 'population', 'recorded_by', 'construction_year', 'extraction_type', 'extraction_type_group', 'extraction_type_class', 'management', 'management_group', 'payment', 'payment_type', 'water_quality', 'quality_group', 'quantity', 'quantity_group', 'source', 'source_type', 'source_class', 'waterpoint_type', 'waterpoint_type_group', 'status_group']\n",
      "A batch of tsh: tf.Tensor(\n",
      "[[  0.]\n",
      " [  0.]\n",
      " [250.]\n",
      " [  0.]\n",
      " [200.]], shape=(5, 1), dtype=float64)\n",
      "A batch of targets: tf.Tensor([0 1 1 0 2], shape=(5,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "[(train_features, label_batch)] = train_ds.take(1)\n",
    "print('Every feature:', list(train_features.keys()))\n",
    "print('A batch of tsh:', train_features['amount_tsh'])\n",
    "print('A batch of targets:', label_batch )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b7bea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a helper function for layer normalization\n",
    "def get_normalization_layer(name, dataset):\n",
    "    # Create a Normalization layer for the feature.\n",
    "    normalizer = layers.Normalization(axis=None)\n",
    "\n",
    "    # Prepare a Dataset that only yields the feature.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "    # Learn the statistics of the data.\n",
    "    normalizer.adapt(feature_ds)\n",
    "\n",
    "    return normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0a4ed2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=float32, numpy=\n",
       "array([[-0.10559317],\n",
       "       [-0.10559317],\n",
       "       [-0.02172938],\n",
       "       [-0.10559317],\n",
       "       [-0.03850214]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing helper function with the \"amount_tsh\" column\n",
    "amount_tsh_col = train_features['amount_tsh']\n",
    "layer = get_normalization_layer('amount_tsh', train_ds)\n",
    "layer(amount_tsh_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "423073a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a helper function for encoding categorical layers\n",
    "def get_category_encoding_layer(name, dataset, dtype, max_tokens=None):\n",
    "    # Create a layer that turns strings into integer indices.\n",
    "    if dtype == 'string':\n",
    "        index = layers.StringLookup(max_tokens=max_tokens)\n",
    "    # Otherwise, create a layer that turns integer values into integer indices.\n",
    "    else:\n",
    "        index = layers.IntegerLookup(max_tokens=max_tokens)\n",
    "\n",
    "    # Prepare a `tf.data.Dataset` that only yields the feature.\n",
    "    feature_ds = dataset.map(lambda x, y: x[name])\n",
    "\n",
    "    # Learn the set of possible values and assign them a fixed integer index.\n",
    "    index.adapt(feature_ds)\n",
    "\n",
    "    # Encode the integer indices.\n",
    "    encoder = layers.CategoryEncoding(num_tokens=index.vocabulary_size())\n",
    "\n",
    "    # Apply multi-hot encoding to the indices. The lambda function captures the\n",
    "    # layer, so you can use them, or include them in the Keras Functional model later.\n",
    "    return lambda feature: encoder(index(feature))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b97a54e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 9), dtype=float32, numpy=\n",
       "array([[0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test helper function for encoding categories\n",
    "test_type_col = train_features['water_quality']\n",
    "test_type_layer = get_category_encoding_layer(name='water_quality',\n",
    "                                              dataset=train_ds,\n",
    "                                              dtype='string')\n",
    "test_type_layer(test_type_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8810c7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y8/vq429chs6djb0hl0y0zp5fg00000gn/T/ipykernel_39053/1929805004.py:5: FutureWarning: Support for multi-dimensional indexing (e.g. `obj[:, None]`) is deprecated and will be removed in a future version.  Convert to a numpy array before indexing instead.\n",
      "  df = {key: value[:,tf.newaxis] for key, value in dataframe.items()}\n"
     ]
    }
   ],
   "source": [
    "# Creating new data sets with larger batch sizes.\n",
    "batch_size = 256\n",
    "train_ds = df_to_dataset(train, batch_size=batch_size)\n",
    "val_ds = df_to_dataset(val, shuffle=False, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc6d2333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the lists of columns\n",
    "# num = any columns with numerical value\n",
    "# ohe = any columns with object value\n",
    "num_cols = []\n",
    "ohe_cols = []\n",
    "\n",
    "for c in X_train.columns:\n",
    "    if X_train[c].dtype in ['float64', 'int64']:\n",
    "        num_cols.append(c)\n",
    "    else:\n",
    "        ohe_cols.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "450370f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "# Numerical features.\n",
    "for header in num_cols:\n",
    "    numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "    normalization_layer = get_normalization_layer(header, train_ds)\n",
    "    encoded_numeric_col = normalization_layer(numeric_col)\n",
    "    all_inputs.append(numeric_col)\n",
    "    encoded_features.append(encoded_numeric_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0f12124",
   "metadata": {},
   "outputs": [],
   "source": [
    "for header in ohe_cols:\n",
    "    categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "    encoding_layer = get_category_encoding_layer(name=header,\n",
    "                                                 dataset=train_ds,\n",
    "                                                 dtype='string',\n",
    "                                                 max_tokens=5)\n",
    "    encoded_categorical_col = encoding_layer(categorical_col)\n",
    "    all_inputs.append(categorical_col)\n",
    "    encoded_features.append(encoded_categorical_col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c988c4f",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "All the preperation is now complete. Time to build and compile the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5f152e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(all_inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "543fe5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de015251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "186/186 [==============================] - 4s 11ms/step - loss: 0.5822 - accuracy: 0.5524 - val_loss: 0.4183 - val_accuracy: 0.7042\n",
      "Epoch 2/20\n",
      "186/186 [==============================] - 2s 7ms/step - loss: 0.4194 - accuracy: 0.6653 - val_loss: 0.2950 - val_accuracy: 0.7103\n",
      "Epoch 3/20\n",
      "186/186 [==============================] - 2s 7ms/step - loss: 0.1084 - accuracy: 0.6768 - val_loss: -0.4130 - val_accuracy: 0.7130\n",
      "Epoch 4/20\n",
      "186/186 [==============================] - 2s 7ms/step - loss: -3.8150 - accuracy: 0.6676 - val_loss: -8.6877 - val_accuracy: 0.6084\n",
      "Epoch 5/20\n",
      "186/186 [==============================] - 2s 7ms/step - loss: -29.0756 - accuracy: 0.6000 - val_loss: -48.2701 - val_accuracy: 0.5224\n",
      "Epoch 6/20\n",
      "186/186 [==============================] - 2s 7ms/step - loss: -107.0667 - accuracy: 0.5402 - val_loss: -147.8600 - val_accuracy: 0.5505\n",
      "Epoch 7/20\n",
      "186/186 [==============================] - 2s 7ms/step - loss: -290.4423 - accuracy: 0.5688 - val_loss: -343.5843 - val_accuracy: 0.6695\n",
      "Epoch 8/20\n",
      "186/186 [==============================] - 2s 7ms/step - loss: -595.9671 - accuracy: 0.5904 - val_loss: -664.7923 - val_accuracy: 0.6872\n",
      "Epoch 9/20\n",
      "186/186 [==============================] - 2s 7ms/step - loss: -1036.0577 - accuracy: 0.5913 - val_loss: -1110.0603 - val_accuracy: 0.6702\n",
      "Epoch 10/20\n",
      "186/186 [==============================] - 2s 7ms/step - loss: -1721.9329 - accuracy: 0.5918 - val_loss: -1778.3513 - val_accuracy: 0.6411\n",
      "Epoch 11/20\n",
      "186/186 [==============================] - 2s 7ms/step - loss: -2617.8477 - accuracy: 0.5904 - val_loss: -2612.5627 - val_accuracy: 0.6554\n",
      "Epoch 12/20\n",
      "186/186 [==============================] - 2s 7ms/step - loss: -3646.5276 - accuracy: 0.5931 - val_loss: -3703.4502 - val_accuracy: 0.6150\n",
      "Epoch 13/20\n",
      "186/186 [==============================] - 2s 7ms/step - loss: -5169.7100 - accuracy: 0.5883 - val_loss: -5029.4634 - val_accuracy: 0.6436\n",
      "Epoch 14/20\n",
      "186/186 [==============================] - 2s 7ms/step - loss: -6687.8511 - accuracy: 0.5913 - val_loss: -6617.2290 - val_accuracy: 0.6443\n",
      "Epoch 15/20\n",
      "186/186 [==============================] - 2s 7ms/step - loss: -8631.2393 - accuracy: 0.5919 - val_loss: -8496.6338 - val_accuracy: 0.6165\n",
      "Epoch 16/20\n",
      "186/186 [==============================] - 2s 6ms/step - loss: -11510.1377 - accuracy: 0.5927 - val_loss: -10890.6104 - val_accuracy: 0.6424\n",
      "Epoch 17/20\n",
      "186/186 [==============================] - 2s 7ms/step - loss: -13943.7012 - accuracy: 0.5937 - val_loss: -13466.3232 - val_accuracy: 0.6537\n",
      "Epoch 18/20\n",
      "186/186 [==============================] - 2s 7ms/step - loss: -18718.9336 - accuracy: 0.5914 - val_loss: -16603.1875 - val_accuracy: 0.5820\n",
      "Epoch 19/20\n",
      "186/186 [==============================] - 2s 7ms/step - loss: -20670.7910 - accuracy: 0.5950 - val_loss: -20021.9395 - val_accuracy: 0.6542\n",
      "Epoch 20/20\n",
      "186/186 [==============================] - 2s 7ms/step - loss: -24795.5605 - accuracy: 0.5928 - val_loss: -23986.4648 - val_accuracy: 0.5655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15a45ff40>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "97af5ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 6ms/step - loss: -1.8417 - accuracy: 0.7335\n",
      "Accuracy 0.733501672744751\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f64edd0",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "The neural network does decently for a first time. I think the neural network would perform much better if I pruned some of the noise. Since I put every single column into the model, it is probably reading too much into some of the less useful features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec4f0fe",
   "metadata": {},
   "source": [
    "## Removing Features\n",
    "Since the amount of features is relativley small, let's only choose features we think may be important this time, and see if that results in improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "68471674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hand selected features\n",
    "num_cols = ['amount_tsh', 'population', 'construction_year']\n",
    "ohe_cols = ['extraction_type', 'management', 'water_quality', 'quantity', 'source', 'waterpoint_type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fe794a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inputs = []\n",
    "encoded_features = []\n",
    "\n",
    "# Numerical features.\n",
    "for header in num_cols:\n",
    "    numeric_col = tf.keras.Input(shape=(1,), name=header)\n",
    "    normalization_layer = get_normalization_layer(header, train_ds)\n",
    "    encoded_numeric_col = normalization_layer(numeric_col)\n",
    "    all_inputs.append(numeric_col)\n",
    "    encoded_features.append(encoded_numeric_col)\n",
    "\n",
    "# Categorical features\n",
    "for header in ohe_cols:\n",
    "    categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='string')\n",
    "    encoding_layer = get_category_encoding_layer(name=header,\n",
    "                                                 dataset=train_ds,\n",
    "                                                 dtype='string',\n",
    "                                                 max_tokens=5)\n",
    "    encoded_categorical_col = encoding_layer(categorical_col)\n",
    "    all_inputs.append(categorical_col)\n",
    "    encoded_features.append(encoded_categorical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f9fb812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "all_features = tf.keras.layers.concatenate(encoded_features)\n",
    "x = tf.keras.layers.Dense(32, activation=\"relu\")(all_features)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "output = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(all_inputs, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04b6662b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "186/186 [==============================] - 3s 8ms/step - loss: 0.5619 - accuracy: 0.5900 - val_loss: 0.4505 - val_accuracy: 0.6955\n",
      "Epoch 2/10\n",
      "186/186 [==============================] - 2s 7ms/step - loss: 0.4605 - accuracy: 0.6716 - val_loss: 0.3989 - val_accuracy: 0.7045\n",
      "Epoch 3/10\n",
      "186/186 [==============================] - 2s 7ms/step - loss: 0.4245 - accuracy: 0.6864 - val_loss: 0.3804 - val_accuracy: 0.7109\n",
      "Epoch 4/10\n",
      "186/186 [==============================] - 2s 7ms/step - loss: 0.4074 - accuracy: 0.6941 - val_loss: 0.3718 - val_accuracy: 0.7120\n",
      "Epoch 5/10\n",
      "186/186 [==============================] - 2s 6ms/step - loss: 0.4020 - accuracy: 0.6954 - val_loss: 0.3669 - val_accuracy: 0.7098\n",
      "Epoch 6/10\n",
      "186/186 [==============================] - 2s 6ms/step - loss: 0.3969 - accuracy: 0.6972 - val_loss: 0.3637 - val_accuracy: 0.7145\n",
      "Epoch 7/10\n",
      "186/186 [==============================] - 2s 7ms/step - loss: 0.3894 - accuracy: 0.7019 - val_loss: 0.3595 - val_accuracy: 0.7163\n",
      "Epoch 8/10\n",
      "186/186 [==============================] - 2s 6ms/step - loss: 0.3875 - accuracy: 0.7024 - val_loss: 0.3568 - val_accuracy: 0.7162\n",
      "Epoch 9/10\n",
      "186/186 [==============================] - 2s 7ms/step - loss: 0.3813 - accuracy: 0.7037 - val_loss: 0.3539 - val_accuracy: 0.7195\n",
      "Epoch 10/10\n",
      "186/186 [==============================] - 2s 6ms/step - loss: 0.3830 - accuracy: 0.7033 - val_loss: 0.3542 - val_accuracy: 0.7182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15a9d61f0>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(train_ds, epochs=10, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b7f4574a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/24 [==============================] - 0s 6ms/step - loss: 0.3712 - accuracy: 0.7145\n",
      "Accuracy 0.7144781351089478\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Accuracy\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b136a44",
   "metadata": {},
   "source": [
    "## Analysis \n",
    "While removing the other features slightly decreased the accuracy of the model, the decrease was not too significant. I think that at this point, it would be more efficent to optimize a different model, deep neur"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KaggleJTP",
   "language": "python",
   "name": "kagglejtp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
